
start a new running with args: Namespace(add_doc_num=319927, batch_size=0, dataset_cache_dir='../../negs_tutorial_cache', dataset_script_dir='../data_scripts', doc_file_path='..//dataset/msmarco-data/msmarco-docs-sents.top.300k.json', docid_path='..//dataset/encoded_docid/t5_atomic_top_300k.txt', epochs=20, learning_rate=0.001, load_ckpt='True', load_ckpt_path='..//outputs/t5_128_10_top_300k_atomic_pretrain/model_0.pkl', log_path='..//logs/search_pretrain.t5_128_10.top.300k.atomic.pretrain_search.log', max_docid_length=1, max_seq_length=64, num_beams=10, operation='training', output_every_n_step=5000, per_gpu_batch_size=100, pretrain_model_path='..//transformer_models/t5-base', save_every_n_epoch=4, save_path='..//outputs/t5_128_10_top_300k_atomic_pretrain_search/', test_file_path='..//dataset/test_data_top_300k/', train_file_path='..//dataset/train_data_top_300k/search_pretrain.t5_128_10.atomic.300k.json', use_docid_rank='False', use_origin_head='False', warmup_ratio=0)

start a new running with args: Namespace(add_doc_num=319927, batch_size=0, dataset_cache_dir='../../negs_tutorial_cache', dataset_script_dir='../data_scripts', doc_file_path='..//dataset/msmarco-data/msmarco-docs-sents.top.300k.json', docid_path='..//dataset/encoded_docid/t5_atomic_top_300k.txt', epochs=20, learning_rate=0.001, load_ckpt='True', load_ckpt_path='..//outputs/t5_128_10_top_300k_atomic_pretrain/model_0.pkl', log_path='..//logs/search_pretrain.t5_128_10.top.300k.atomic.pretrain_search.log', max_docid_length=1, max_seq_length=64, num_beams=10, operation='training', output_every_n_step=5000, per_gpu_batch_size=100, pretrain_model_path='..//transformer_models/t5-base', save_every_n_epoch=4, save_path='..//outputs/t5_128_10_top_300k_atomic_pretrain_search/', test_file_path='..//dataset/test_data_top_300k/', train_file_path='..//dataset/train_data_top_300k/search_pretrain.t5_128_10.atomic.300k.json', use_docid_rank='False', use_origin_head='False', warmup_ratio=0)

start a new running with args: Namespace(add_doc_num=319927, batch_size=0, dataset_cache_dir='../../negs_tutorial_cache', dataset_script_dir='../data_scripts', doc_file_path='..//dataset/msmarco-data/msmarco-docs-sents.top.300k.json', docid_path='..//dataset/encoded_docid/t5_atomic_top_300k.txt', epochs=20, learning_rate=0.001, load_ckpt='True', load_ckpt_path='..//outputs/t5_128_10_top_300k_atomic_pretrain/model_0.pkl', log_path='..//logs/search_pretrain.t5_128_10.top.300k.atomic.pretrain_search.log', max_docid_length=1, max_seq_length=64, num_beams=10, operation='training', output_every_n_step=5000, per_gpu_batch_size=100, pretrain_model_path='..//transformer_models/t5-base', save_every_n_epoch=4, save_path='..//outputs/t5_128_10_top_300k_atomic_pretrain_search/', test_file_path='..//dataset/test_data_top_300k/', train_file_path='..//dataset/train_data_top_300k/search_pretrain.t5_128_10.atomic.300k.json', use_docid_rank='False', use_origin_head='False', warmup_ratio=0)

start a new running with args: Namespace(add_doc_num=319927, batch_size=0, dataset_cache_dir='../../negs_tutorial_cache', dataset_script_dir='../data_scripts', doc_file_path='../dataset/msmarco-data/msmarco-docs-sents.top.300k.json', docid_path='../dataset/encoded_docid/t5_atomic_top_300k.txt', epochs=20, learning_rate=0.001, load_ckpt='True', load_ckpt_path='../outputs/t5_128_10_top_300k_atomic_pretrain/model_0.pkl', log_path='../logs/search_pretrain.t5_128_10.top.300k.atomic.pretrain_search.log', max_docid_length=1, max_seq_length=64, num_beams=10, operation='training', output_every_n_step=5000, per_gpu_batch_size=100, pretrain_model_path='../transformer_models/t5-base', save_every_n_epoch=4, save_path='../outputs/t5_128_10_top_300k_atomic_pretrain_search/', test_file_path='../dataset/test_data_top_300k/', train_file_path='../dataset/train_data_top_300k/search_pretrain.t5_128_10.atomic.300k.json', use_docid_rank='False', use_origin_head='False', warmup_ratio=0)

start a new running with args: Namespace(add_doc_num=319927, batch_size=0, dataset_cache_dir='../../negs_tutorial_cache', dataset_script_dir='../data_scripts', doc_file_path='../dataset/msmarco-data/msmarco-docs-sents.top.300k.json', docid_path='../dataset/encoded_docid/t5_atomic_top_300k.txt', epochs=20, learning_rate=0.001, load_ckpt='True', load_ckpt_path='../outputs/t5_128_10_top_300k_atomic_pretrain/model_0.pkl', log_path='../logs/search_pretrain.t5_128_10.top.300k.atomic.pretrain_search.log', max_docid_length=1, max_seq_length=64, num_beams=10, operation='training', output_every_n_step=5000, per_gpu_batch_size=100, pretrain_model_path='../transformer_models/t5-base', save_every_n_epoch=4, save_path='../outputs/t5_128_10_top_300k_atomic_pretrain_search/', test_file_path='../dataset/test_data_top_300k/', train_file_path='../dataset/train_data_top_300k/search_pretrain.t5_128_10.atomic.300k.json', use_docid_rank='False', use_origin_head='False', warmup_ratio=0)

start a new running with args: Namespace(add_doc_num=319927, batch_size=0, dataset_cache_dir='../../negs_tutorial_cache', dataset_script_dir='../data_scripts', doc_file_path='../dataset/msmarco-data/msmarco-docs-sents.top.300k.json', docid_path='../dataset/encoded_docid/t5_atomic_top_300k.txt', epochs=20, learning_rate=0.001, load_ckpt='True', load_ckpt_path='../outputs/t5_128_10_top_300k_atomic_pretrain/model_0.pkl', log_path='../logs/search_pretrain.t5_128_10.top.300k.atomic.pretrain_search.log', max_docid_length=1, max_seq_length=64, num_beams=10, operation='training', output_every_n_step=5000, per_gpu_batch_size=100, pretrain_model_path='../transformer_models/t5-base', save_every_n_epoch=4, save_path='../outputs/t5_128_10_top_300k_atomic_pretrain_search/', test_file_path='../dataset/test_data_top_300k/', train_file_path='../dataset/train_data_top_300k/search_pretrain.t5_128_10.atomic.300k.json', use_docid_rank='False', use_origin_head='False', warmup_ratio=0)

start a new running with args: Namespace(add_doc_num=319927, batch_size=0, dataset_cache_dir='../../negs_tutorial_cache', dataset_script_dir='../data_scripts', doc_file_path='../dataset/msmarco-data/msmarco-docs-sents.top.300k.json', docid_path='../dataset/encoded_docid/t5_atomic_top_300k.txt', epochs=20, learning_rate=0.001, load_ckpt='True', load_ckpt_path='../outputs/t5_128_10_top_300k_atomic_pretrain/model_0.pkl', log_path='../logs/search_pretrain.t5_128_10.top.300k.atomic.pretrain_search.log', max_docid_length=1, max_seq_length=64, num_beams=10, operation='training', output_every_n_step=5000, per_gpu_batch_size=100, pretrain_model_path='../transformer_models/t5-base', save_every_n_epoch=4, save_path='../outputs/t5_128_10_top_300k_atomic_pretrain_search/', test_file_path='../dataset/test_data_top_300k/', train_file_path='../dataset/train_data_top_300k/search_pretrain.t5_128_10.atomic.300k.json', use_docid_rank='False', use_origin_head='False', warmup_ratio=0)

start a new running with args: Namespace(epochs=20, per_gpu_batch_size=100, learning_rate=0.001, warmup_ratio=0, output_every_n_step=5000, save_every_n_epoch=4, operation='training', use_docid_rank='False', load_ckpt='True', save_path='../outputs/t5_128_10_top_300k_atomic_pretrain_search/', log_path='../logs/search_pretrain.t5_128_10.top.300k.atomic.pretrain_search.log', doc_file_path='../dataset/msmarco-data/msmarco-docs-sents.top.300k.json', docid_path='../dataset/encoded_docid/t5_atomic_top_300k.txt', train_file_path='../dataset/train_data_top_300k/search_pretrain.t5_128_10.atomic.300k.json', test_file_path='../dataset/test_data_top_300k/', pretrain_model_path='../transformer_models/t5-base', load_ckpt_path='../outputs/t5_128_10_top_300k_atomic_pretrain/model_0.pkl', dataset_script_dir='../data_scripts', dataset_cache_dir='../../negs_tutorial_cache', add_doc_num=319927, max_seq_length=64, max_docid_length=1, use_origin_head='False', num_beams=10, batch_size=200)

start a new running with args: Namespace(epochs=20, per_gpu_batch_size=100, learning_rate=0.001, warmup_ratio=0, output_every_n_step=5000, save_every_n_epoch=4, operation='training', use_docid_rank='False', load_ckpt='True', save_path='../outputs/t5_128_10_top_300k_atomic_pretrain_search/', log_path='../logs/search_pretrain.t5_128_10.top.300k.atomic.pretrain_search.log', doc_file_path='../dataset/msmarco-data/msmarco-docs-sents.top.300k.json', docid_path='../dataset/encoded_docid/t5_atomic_top_300k.txt', train_file_path='../dataset/train_data_top_300k/search_pretrain.t5_128_10.atomic.300k.json', test_file_path='../dataset/test_data_top_300k/', pretrain_model_path='../transformer_models/t5-base', load_ckpt_path='../outputs/t5_128_10_top_300k_atomic_pretrain/model_0.pkl', dataset_script_dir='../data_scripts', dataset_cache_dir='../../negs_tutorial_cache', add_doc_num=319927, max_seq_length=64, max_docid_length=1, use_origin_head='False', num_beams=10, batch_size=200)

start a new running with args: Namespace(epochs=20, per_gpu_batch_size=100, learning_rate=0.001, warmup_ratio=0, output_every_n_step=5000, save_every_n_epoch=4, operation='training', use_docid_rank='False', load_ckpt='True', save_path='../outputs/t5_128_10_top_300k_atomic_pretrain_search/', log_path='../logs/search_pretrain.t5_128_10.top.300k.atomic.pretrain_search.log', doc_file_path='../dataset/msmarco-data/msmarco-docs-sents.top.300k.json', docid_path='../dataset/encoded_docid/t5_atomic_top_300k.txt', train_file_path='../dataset/train_data_top_300k/search_pretrain.t5_128_10.atomic.300k.json', test_file_path='../dataset/test_data_top_300k/', pretrain_model_path='../transformer_models/t5-base', load_ckpt_path='../outputs/t5_128_10_top_300k_atomic_pretrain/model_0.pkl', dataset_script_dir='../data_scripts', dataset_cache_dir='../../negs_tutorial_cache', add_doc_num=319927, max_seq_length=64, max_docid_length=1, use_origin_head='False', num_beams=10, batch_size=200)

start a new running with args: Namespace(epochs=20, per_gpu_batch_size=100, learning_rate=0.001, warmup_ratio=0, output_every_n_step=5000, save_every_n_epoch=4, operation='training', use_docid_rank='False', load_ckpt='True', save_path='../outputs/t5_128_10_top_300k_atomic_pretrain_search/', log_path='../logs/search_pretrain.t5_128_10.top.300k.atomic.pretrain_search.log', doc_file_path='../dataset/msmarco-data/msmarco-docs-sents.top.300k.json', docid_path='../dataset/encoded_docid/t5_atomic_top_300k.txt', train_file_path='../dataset/train_data_top_300k/search_pretrain.t5_128_10.atomic.300k.json', test_file_path='../dataset/test_data_top_300k/', pretrain_model_path='../transformer_models/t5-base', load_ckpt_path='../outputs/t5_128_10_top_300k_atomic_pretrain/model_0.pkl', dataset_script_dir='../data_scripts', dataset_cache_dir='../../negs_tutorial_cache', add_doc_num=319927, max_seq_length=64, max_docid_length=1, use_origin_head='False', num_beams=10, batch_size=200)

start a new running with args: Namespace(epochs=20, per_gpu_batch_size=100, learning_rate=0.001, warmup_ratio=0, output_every_n_step=5000, save_every_n_epoch=4, operation='training', use_docid_rank='False', load_ckpt='True', save_path='../outputs/t5_128_10_top_300k_atomic_pretrain_search/', log_path='../logs/search_pretrain.t5_128_10.top.300k.atomic.pretrain_search.log', doc_file_path='../dataset/msmarco-data/msmarco-docs-sents.top.300k.json', docid_path='../dataset/encoded_docid/t5_atomic_top_300k.txt', train_file_path='../dataset/train_data_top_300k/search_pretrain.t5_128_10.atomic.300k.json', test_file_path='../dataset/test_data_top_300k/', pretrain_model_path='../transformer_models/t5-base', load_ckpt_path='../outputs/t5_128_10_top_300k_atomic_pretrain/model_0.pkl', dataset_script_dir='../data_scripts', dataset_cache_dir='../../negs_tutorial_cache', add_doc_num=319927, max_seq_length=64, max_docid_length=1, use_origin_head='False', num_beams=10, batch_size=200)

start a new running with args: Namespace(epochs=20, per_gpu_batch_size=100, learning_rate=0.001, warmup_ratio=0, output_every_n_step=5000, save_every_n_epoch=4, operation='training', use_docid_rank='False', load_ckpt='True', save_path='../outputs/t5_128_10_top_300k_atomic_pretrain_search/', log_path='../logs/search_pretrain.t5_128_10.top.300k.atomic.pretrain_search.log', doc_file_path='../dataset/msmarco-data/msmarco-docs-sents.top.300k.json', docid_path='../dataset/encoded_docid/t5_atomic_top_300k.txt', train_file_path='../dataset/train_data_top_300k/search_pretrain.t5_128_10.atomic.300k.json', test_file_path='../dataset/test_data_top_300k/', pretrain_model_path='../transformer_models/t5-base', load_ckpt_path='../outputs/t5_128_10_top_300k_atomic_pretrain/model_0.pkl', dataset_script_dir='../data_scripts', dataset_cache_dir='../../negs_tutorial_cache', add_doc_num=319927, max_seq_length=64, max_docid_length=1, use_origin_head='False', num_beams=10, batch_size=200)

start a new running with args: Namespace(epochs=20, per_gpu_batch_size=1, learning_rate=0.001, warmup_ratio=0, output_every_n_step=5000, save_every_n_epoch=4, operation='training', use_docid_rank='False', load_ckpt='True', save_path='../outputs/t5_128_10_top_300k_atomic_pretrain_search/', log_path='../logs/search_pretrain.t5_128_10.top.300k.atomic.pretrain_search.log', doc_file_path='../dataset/msmarco-data/msmarco-docs-sents.top.300k.json', docid_path='../dataset/encoded_docid/t5_atomic_top_300k.txt', train_file_path='../dataset/train_data_top_300k/search_pretrain.t5_128_10.atomic.300k.json', test_file_path='../dataset/test_data_top_300k/', pretrain_model_path='../transformer_models/t5-base', load_ckpt_path='../outputs/t5_128_10_top_300k_atomic_pretrain/model_0.pkl', dataset_script_dir='../data_scripts', dataset_cache_dir='../../negs_tutorial_cache', add_doc_num=319927, max_seq_length=64, max_docid_length=1, use_origin_head='False', num_beams=10, batch_size=2)
